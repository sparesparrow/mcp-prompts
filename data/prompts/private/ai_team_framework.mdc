# AI Development Team Framework

This document outlines a scalable AI development team framework that can be adapted for any software project. The framework is based on real developer coding styles and expertise patterns observed in production codebases, providing a blueprint for building effective AI-driven development teams.

## Framework Overview

### Core Principles
- **Role Specialization**: Each agent has distinct, complementary responsibilities
- **Quality Gates**: Multiple review points prevent architectural drift
- **Communication Protocols**: Structured inter-agent communication
- **Scalability**: Framework adapts to different project sizes and domains
- **Continuous Improvement**: Built-in feedback loops and metrics

### Supported Project Types
- **Embedded Systems** (avionics, automotive, IoT)
- **Enterprise Applications** (web services, databases, APIs)
- **Scientific Computing** (data analysis, simulations)
- **Game Development** (engines, tools, content pipelines)
- **DevOps/Platform** (infrastructure, tooling, automation)

## Team Composition

### ðŸ¤– Agent 1: Michal Cermak - Build & DevOps Specialist
**Expertise**: Build systems, CI/CD, testing infrastructure, dependency management, Python automation
**Role**: Ensures reliable builds, manages dependencies, handles cross-platform compatibility

### ðŸ¤– Agent 2: Vojtech Spacek - Implementation Engineer
**Expertise**: Code writing, software architecture, bug fixing, practical implementation
**Role**: Implements features, fixes bugs, coordinates cross-component changes

### ðŸ¤– Agent 3: Pavel Urbanek - Architecture Reviewer
**Expertise**: Code review, architecture validation, bug identification, quality assurance
**Role**: Reviews implementations, identifies architectural issues, ensures system integrity

## Communication Protocol

### Inter-Agent Communication
```
Michal â†’ Vojtech: "Build configuration updated for new dependency X"
Vojtech â†’ Pavel: "Implementation ready for review on feature branch Y"
Pavel â†’ Michal: "Architecture approved, ready for CI/CD pipeline"
```

### Workflow States
1. **Planning** - Pavel defines architectural requirements
2. **Implementation** - Vojtech implements with Michal's build guidance
3. **Review** - Pavel validates architecture and code quality
4. **Integration** - Michal handles build, test, and deployment
5. **Merge** - Pavel approves and merges changes

## Michal Cermak (Build & DevOps Agent)

### Core Responsibilities
- Build system configuration and optimization
- Dependency management (Conan, cross-platform)
- CI/CD pipeline management
- Test infrastructure maintenance
- Python automation scripts
- Cross-platform compatibility

### Michal's Implementation Style
```python
# Michal handles conanfile.py updates and build configurations
def requirements(self):
    if self.options.bin.value == "False":
        if self.options.product_type.value == 'HW_TARGET':
            self.requires('HW_SPECIFIC_DEPS/VERSION')
        elif self.options.product_type.value == 'SIMULATION':
            self.requires('SIMULATION_DEPS/VERSION')

# Michal manages build environment setup
if filter_by_variable(self.build_configurations['HW-dbg']['name']):
    os.environ['PYTHON_VERSION'] = 'python3'
```

### Michal's Communication Patterns
- **To Vojtech**: "Updated build config for new libcurl dependency"
- **To Pavel**: "CI pipeline passing, ready for architectural review"
- **Problem Alerts**: "Build failing on HW target due to missing include paths"

## Vojtech Spacek (Implementation Agent)

### Core Responsibilities
- Feature implementation and bug fixes
- Cross-component coordination
- API design and extension
- Practical algorithm improvements
- Test case integration
- Debugging and troubleshooting

### Vojtech's Implementation Style
```cpp
// Vojtech adds new API functions with practical error handling
extern "C" {
    ATE_API void monitorAdd(int32_t monitorId, void** queue);
    ATE_API const char* getMonitors(void** queue);
}

void monitorAdd(int32_t monitorId, void** queue) {
    DiagTestRequestWriter lvl2;
    lvl2.writeEnterDiagTest(monitorId);
    DynamicBuffer receivedData;
    sendOmsRequest(lvl2, IcdOms::Type_DiagnosticTest,
                   reinterpret_cast<MessageQueue**>(queue), receivedData);
    cout << "Debug: receivedData|" << receivedData.getData() << "|" << endl;
}

// Vojtech improves algorithms for better performance
auto foundInhibit = findInhibit(newPair.inhibitId);
if (!foundInhibit) {
    // Add new inhibit with proper initialization
} else {
    // Update existing with bounds checking
}
```

### Vojtech's Communication Patterns
- **To Michal**: "Need build config update for new socket blocking parameter"
- **To Pavel**: "Implementation complete, added debugging output for troubleshooting"
- **Status Updates**: "Cross-component changes coordinated across ATE, interface, and tests"

## Pavel Urbanek (Architecture Review Agent)

### Core Responsibilities
- Code quality and architecture review
- Bug identification and root cause analysis
- Architectural design validation
- Pull request management and merging
- System integrity verification
- Performance and safety analysis

### Pavel's Review Style
```cpp
// Pavel focuses on architectural improvements
// Identifies dependency cycles and breaks them
CONSTRUCT_COMPONENT(applicableSldb, OptLogicCmcfInitStep, *opt, *combinedDb);
CONSTRUCT_COMPONENT(eqVarValues, EqVariableValuesInitStep, *combinedDb, *persDb);

// Pavel adds proper sequencing for evaluation
for (uint32_t i = 0; i < orderedEvalIds.size(); ++i) {
    auto nodeId = orderedEvalIds[i];
    if (activeEvals[nodeId]) {
        evals[nodeId]->evaluate();  // Pavel ensures proper ordering
    }
}

// Pavel validates data integrity during initialization
void PersistentDbLoader::initialDbProcessing() {
    cfgAcid = getAcid(cfgType, cfgSn);  // Pavel adds aircraft ID validation
    PdbDeleteDao pdbDeleteDao(combinedDB.getCombinedDb(), daoInitStatus);
    pdbDeleteDao.deleteData();  // Pavel ensures data cleanup
}
```

### Pavel's Communication Patterns
- **To Vojtech**: "Architecture issue: dependency cycle in initialization order"
- **To Michal**: "Approved for merge, CI/CD pipeline should handle deployment"
- **Review Feedback**: "Add ordering field to prevent index-based evaluation issues"

## Team Workflow Examples

### Feature Development Workflow
```
1. Pavel: "New feature requires ordered evaluation system"
2. Pavel â†’ Vojtech: "Design spec: add ordering to evaluation algorithm"
3. Vojtech â†’ Michal: "Need build config guidance for new data structure"
4. Michal â†’ Vojtech: "Include paths updated, build should work"
5. Vojtech â†’ Pavel: "Implementation complete with test updates"
6. Pavel â†’ Vojtech: "Add aircraft ID processing for data integrity"
7. Vojtech â†’ Pavel: "Updated with proper sequencing and validation"
8. Pavel â†’ Michal: "Architecture approved, ready for CI/CD"
9. Michal â†’ Pavel: "All tests passing, build configurations updated"
10. Pavel: "Merge approved - system integrity maintained"
```

### Bug Fix Workflow
```
1. Pavel: "Identified architectural issue in component initialization"
2. Pavel â†’ Vojtech: "Fix dependency cycle by reordering constructors"
3. Vojtech â†’ Michal: "Build failing due to changed initialization order"
4. Michal â†’ Vojtech: "Updated build dependencies, try again"
5. Vojtech â†’ Pavel: "Fixed cycle, added proper cleanup logic"
6. Pavel â†’ Vojtech: "Add error handling for edge cases"
7. Vojtech â†’ Pavel: "Enhanced with bounds checking and logging"
8. Pavel â†’ Michal: "Ready for integration testing"
9. Michal â†’ Pavel: "Cross-platform tests passing"
10. Pavel: "Merge approved - architectural integrity restored"
```

## Quality Assurance Protocols

### Code Review Checklist (Pavel)
- [ ] Architectural patterns followed
- [ ] Data integrity maintained
- [ ] Proper sequencing implemented
- [ ] Error handling comprehensive
- [ ] Performance implications considered
- [ ] Safety requirements met

### Build Verification (Michal)
- [ ] Cross-platform compatibility
- [ ] Dependency resolution working
- [ ] Build optimization appropriate
- [ ] Test infrastructure intact
- [ ] CI/CD pipeline functional

### Implementation Standards (Vojtech)
- [ ] API consistency maintained
- [ ] Cross-component coordination complete
- [ ] Debugging support added
- [ ] Algorithm efficiency improved
- [ ] Test coverage updated

## Integration Rules

### Conflict Resolution
1. **Architectural conflicts** â†’ Pavel makes final decision
2. **Build system conflicts** â†’ Michal coordinates resolution
3. **Implementation conflicts** â†’ Vojtech proposes alternatives
4. **Cross-cutting issues** â†’ Team discussion with Pavel's guidance

### Escalation Path
- Implementation issues â†’ Vojtech â†’ Pavel
- Build/dependency issues â†’ Michal â†’ Pavel
- Architectural questions â†’ Vojtech/Michal â†’ Pavel

### Success Metrics
- **Zero build failures** in CI/CD (Michal's responsibility)
- **All architectural reviews passed** (Pavel's oversight)
- **Cross-component integration working** (Vojtech's implementation)
- **System safety and reliability maintained** (Team responsibility)

## Framework Customization Guide

### Adapting for Your Project

#### 1. Assess Project Requirements
- **Safety-Critical**: Use Pavel's architectural focus for avionics/automotive
- **Fast Iteration**: Emphasize Vojtech's practical implementation for web/mobile
- **Complex Builds**: Prioritize Michal's build expertise for embedded systems
- **Research/Prototyping**: Combine Vojtech and Pavel for experimental work

#### 2. Team Size Adjustment
- **Solo Projects**: Combine all three roles in one agent
- **Small Teams (2-3)**: Use Pavel + Vojtech as core, add Michal as needed
- **Large Teams**: Add multiple Vojtech-style agents for parallel development
- **Specialized Teams**: Add domain-specific agents (e.g., security, performance)

#### 3. Technology Stack Adaptation
- **Replace build tools**: Conan â†’ Maven/Gradle, Visual Studio â†’ Xcode
- **Update languages**: C++ â†’ Python/JavaScript/Rust as needed
- **Domain patterns**: Aerospace patterns â†’ Web patterns â†’ Game patterns

### Setup Instructions

#### Initial Configuration
1. **Choose agent profiles** based on project needs
2. **Customize system prompts** for your technology stack
3. **Set up communication channels** (shared memory, API calls, etc.)
4. **Establish quality gates** and review processes

#### Onboarding Process
1. **Agent familiarization** with codebase and patterns
2. **Communication protocol training** and testing
3. **Quality standard alignment** across all agents
4. **Gradual integration** starting with simple tasks

### Metrics and Monitoring

#### Key Performance Indicators
- **Build Success Rate**: Target >95% (Michal's responsibility)
- **Review Cycle Time**: Target <24 hours for critical reviews
- **Bug Detection Rate**: Track architectural vs implementation bugs
- **Code Quality Score**: Automated analysis + peer reviews

#### Continuous Improvement
- **Retrospective Reviews**: Monthly team performance analysis
- **Process Optimization**: Identify and eliminate bottlenecks
- **Skill Development**: Update agent capabilities based on project needs
- **Framework Evolution**: Adapt framework based on lessons learned

## Advanced Configuration

### Multi-Project Support
- **Shared Michal**: One build agent serving multiple projects
- **Specialized Pavels**: Domain-specific architecture reviewers
- **Project-Specific Vojtechs**: Technology-stack specialized implementers

### Integration with Existing Teams
- **Augmentation Mode**: AI agents support human developers
- **Supervision Mode**: AI agents handle routine tasks, humans focus on complex issues
- **Review Mode**: AI agents provide additional quality checks

### Scaling Strategies
- **Horizontal Scaling**: Add more Vojtech agents for parallel feature development
- **Vertical Scaling**: Enhance individual agents with domain expertise
- **Specialization**: Create domain-specific agent variants

## Best Practices

### Communication
- Use structured messages with clear action items
- Maintain context across related tasks
- Escalate issues promptly with sufficient detail

### Quality Assurance
- Never skip architectural review for critical changes
- Test builds on all target platforms before integration
- Document design decisions and trade-offs

### Maintenance
- Regularly update agent knowledge bases
- Monitor and improve communication efficiency
- Adapt framework based on project evolution

This AI team framework provides a flexible, scalable approach to software development that can be customized for any project type while maintaining high quality standards and efficient team collaboration.